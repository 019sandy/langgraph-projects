{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c9c7da",
   "metadata": {},
   "source": [
    "## ``Langgraph``\n",
    "1. Graph :\n",
    "2. State Machine : manage sequence \n",
    "    - State are Nodes\n",
    "    - Transition are Edges\n",
    "3. Langgraph : \n",
    "    - can describe our flows using nodes and Edges , and can build Agentic Application\n",
    "    \n",
    "4. Flow Engineering :\n",
    "    - complex decison making nodes and edges , may be iterative cycle\n",
    "    - guides AI system with guided steps , that mimics human software Engineering\n",
    "    - We humans will define the FLow. LLM will take decisions at interim level and LLM will \n",
    "      work within the FLow that we created.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098c760",
   "metadata": {},
   "source": [
    "## ``Langgraph Core Components``\n",
    "1. ``Node``: python functions - Any Python Code\n",
    "2. ``Edges``: Edges connects those nodes within the graph execution\n",
    "3. ``Conditional Edges``: They help making decisons weather to go to Node A , or to Node B\n",
    "4. ``built in Nodes`` : start ( entrypoint of graph execution ) and end ( last node )\n",
    "\n",
    "5. ``Agent State``: It is a ``Dictionary`` that keeps information that we need to keep track in the graph . Like some node results , chat history , etc. etc. \n",
    "    - It is local to the graph and is available only during the Graph Execution.\n",
    "    - Available on each edge as well\n",
    "    - We can keep the ``State`` in ``Persistence`` , so it is not temporarily available\n",
    "\n",
    "### ``Nodes`` will always receives as the Input the current Graph State ( state: GraphState) which is all the information the Node needs in order to do it's work. and it always returns the keys of the Dictionary of we ultimately wants to update in the State once node is Executed.\n",
    "\n",
    "\n",
    "6. ``Cyclic Graph`` : Loops\n",
    "7. ``Human in the Loop`` : human apprvals \n",
    "8. ``Persistence`` : Langgraph has built in functions which helps us persist the State of the Graphs.\n",
    "\n",
    "\n",
    "- ``Course here`` - https://github.com/emarco177/langgraph-course/tree/main\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d45522",
   "metadata": {},
   "source": [
    "## ``Section 2 - Reflection Agent``\n",
    "1. Reflection Agents enhance the quality of success rates of Agents answers . They ask LLM to reflect to its responses and allows it to learn and improve it over time.\n",
    "2. What we will do here :\n",
    "    - Reflection Agent will take our Tweet\n",
    "    - It will give us a critique with a reflection step\n",
    "    - Will give the feedback and criticise our twitter post\n",
    "    - We will take this feedback , feed it into LLM adn will ask it to revise.\n",
    "    - Revision number 1 and this will continue.\n",
    "\n",
    "## ``Section 2.1 - Project Setup``\n",
    "1. Create project directory :\n",
    "    - mkdir reflection-agent\n",
    "    - cd to this directory\n",
    "2. use Poetry to create Virtual Env :\n",
    "    - poetry init , and just hit enter for all options\n",
    "    - It generates project.toml file with basic structure\n",
    "    - Install all dependencies in the poetry env now:\n",
    "        - poetry add python-dotenv black isort langchain langchain-openai langgraph\n",
    "        - it generates project.toml file as base file , and whatever we will install will get added here , poetry.   lock will have all installation details.\n",
    "3. Install dependencies\n",
    "4. configure our VSC\n",
    "5. env to load Langsmith API keys , OpenAI API KEys , etc \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
